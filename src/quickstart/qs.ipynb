{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74fd2394be35f78",
   "metadata": {},
   "source": [
    "# langChain Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffba68acc943b36",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "### Environment and APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:34:26.963598Z",
     "start_time": "2024-03-28T15:34:26.938673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import os\n",
    "# print ('LANGCHAIN_API_KEY: ', os.getenv('LANGCHAIN_API_KEY'))\n",
    "# print ('OPENAI_API_KEY: ', os.getenv('OPENAI_API_KEY'))\n",
    "# print ('TAVILY_API_KEY: ', os.getenv('TAVILY_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b50dcfc6ba077",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903ede1b9c4d13ee",
   "metadata": {
    "hide_input": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:34:43.922029Z",
     "start_time": "2024-03-28T15:34:35.963492Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be699dec8c0ca6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Docstore pre-load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc782a67da65854",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:34:49.254858Z",
     "start_time": "2024-03-28T15:34:47.595614Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "docs = loader.load()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56228206d6a717e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chains - Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1087934247e7c772",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:34:53.884404Z",
     "start_time": "2024-03-28T15:34:53.785580Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "doc_prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "document_chain = create_stuff_documents_chain(chat_model, doc_prompt)\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425c900bdf1f83e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_TEST - retrieval_chain_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29dd15af6e4065",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee85cd4b5b29ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chains - History Aware Retrieval\n",
    "### Generate search from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37d248a251ae615",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:35:00.925540Z",
     "start_time": "2024-03-28T15:35:00.919633Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "search_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to lookup in order to get information relevant to the conversation.\")\n",
    "])\n",
    "history_retriever_chain = create_history_aware_retriever(chat_model, retriever, search_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcdb599f05f1e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generate answer from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349094988512247b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:35:06.088312Z",
     "start_time": "2024-03-28T15:35:06.083243Z"
    }
   },
   "outputs": [],
   "source": [
    "history_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(chat_model, history_prompt)\n",
    "history_chain = create_retrieval_chain(history_retriever_chain, document_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cc104870214f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_TEST - history_chain_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a8be1a891d713",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6708cfc2f3077",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Agent\n",
    "### Search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1334a2525e2ad9a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:35:13.658332Z",
     "start_time": "2024-03-28T15:35:13.640923Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:35:17.177837Z",
     "start_time": "2024-03-28T15:35:17.174698Z"
    }
   },
   "id": "62d930132434c0f9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import langchainhub, please install with `pip install langchainhub`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/miniconda3/envs/MLBase/lib/python3.10/site-packages/langchain/hub.py:18\u001B[0m, in \u001B[0;36m_get_client\u001B[0;34m(api_url, api_key)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchainhub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Client\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'langchainhub'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01magents\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_openai_functions_agent\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01magents\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AgentExecutor\n\u001B[0;32m----> 5\u001B[0m agent_prompt \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpull\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhwchase17/openai-functions-agent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m agent_chat_model \u001B[38;5;241m=\u001B[39m ChatOpenAI(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      7\u001B[0m agent \u001B[38;5;241m=\u001B[39m create_openai_functions_agent(agent_chat_model, agent_prompt, tools)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/MLBase/lib/python3.10/site-packages/langchain/hub.py:82\u001B[0m, in \u001B[0;36mpull\u001B[0;34m(owner_repo_commit, api_url, api_key)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpull\u001B[39m(\n\u001B[1;32m     68\u001B[0m     owner_repo_commit: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m     70\u001B[0m     api_url: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     71\u001B[0m     api_key: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     72\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m     73\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124;03m    Pulls an object from the hub and returns it as a LangChain object.\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;124;03m    :param api_key: The API key to use to authenticate with the LangChain Hub API.\u001B[39;00m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 82\u001B[0m     client \u001B[38;5;241m=\u001B[39m \u001B[43m_get_client\u001B[49m\u001B[43m(\u001B[49m\u001B[43mapi_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(client, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpull_repo\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;66;03m# >= 0.1.15\u001B[39;00m\n\u001B[1;32m     86\u001B[0m         res_dict \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mpull_repo(owner_repo_commit)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/MLBase/lib/python3.10/site-packages/langchain/hub.py:20\u001B[0m, in \u001B[0;36m_get_client\u001B[0;34m(api_url, api_key)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchainhub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Client\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m---> 20\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not import langchainhub, please install with `pip install \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlangchainhub`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     23\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Client logic will also attempt to load URL/key from environment variables\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Client(api_url, api_key\u001B[38;5;241m=\u001B[39mapi_key)\n",
      "\u001B[0;31mImportError\u001B[0m: Could not import langchainhub, please install with `pip install langchainhub`."
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(agent_chat_model, agent_prompt, tools)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:38:32.450414Z",
     "start_time": "2024-03-28T15:38:32.405240Z"
    }
   },
   "id": "9836b3bec4b9ca89",
   "execution_count": 10
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "32",
    "lenType": 16,
    "lenVar": "1024"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
