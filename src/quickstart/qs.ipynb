{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74fd2394be35f78",
   "metadata": {},
   "source": [
    "# langChain Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffba68acc943b36",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "### Environment and APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import os\n",
    "# print ('LANGCHAIN_API_KEY: ', os.getenv('LANGCHAIN_API_KEY'))\n",
    "# print ('OPENAI_API_KEY: ', os.getenv('OPENAI_API_KEY'))\n",
    "# print ('TAVILY_API_KEY: ', os.getenv('TAVILY_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b50dcfc6ba077",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ede1b9c4d13ee",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be699dec8c0ca6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Docstore pre-load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc782a67da65854",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "docs = loader.load()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56228206d6a717e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chains - Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087934247e7c772",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "doc_prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "document_chain = create_stuff_documents_chain(chat_model, doc_prompt)\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425c900bdf1f83e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_TEST - retrieval_chain_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29dd15af6e4065",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee85cd4b5b29ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chains - History Aware Retrieval\n",
    "### Generate search from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d248a251ae615",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "search_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to lookup in order to get information relevant to the conversation.\")\n",
    "])\n",
    "history_retriever_chain = create_history_aware_retriever(chat_model, retriever, search_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcdb599f05f1e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generate answer from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349094988512247b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(chat_model, history_prompt)\n",
    "history_chain = create_retrieval_chain(history_retriever_chain, document_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cc104870214f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_TEST - history_chain_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a8be1a891d713",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6708cfc2f3077",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Agent\n",
    "### Search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1334a2525e2ad9a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d930132434c0f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836b3bec4b9ca89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(agent_chat_model, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "444ade6b0cc7bf82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the weather in SF?\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22f1b5355ba8654c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "agent_executor.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ca48dd3ac3066ed",
   "execution_count": null
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "32",
    "lenType": 16,
    "lenVar": "1024"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
